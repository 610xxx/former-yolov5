# YOLOv5 🚀 by Ultralytics, GPL-3.0 license

# Parameters    efficentnetv2通过搜索能依据训练大小自适应调整正则化参数--（）
nc: 80  # number of classes
depth_multiple: 1.0  # model depth multiple
width_multiple: 1.0  # layer channel multiple  L /44GFLOPS     fusedmbconv/mbconv深度可分离扩张卷积，本质还是轻量级别得的网络，受限移动设备，网络复杂度低
anchors:
  # - [10,13, 16,30, 33,23]  # P3/8
  # - [30,61, 62,45, 59,119]  # P4/16
  # - [116,90, 156,198, 373,326]  # P5/32

   - [5,6, 9,4, 7,9] #小 face
   - [19,8, 11,14, 33,19]
   - [23,32, 56,29, 89,43] #高  plate

# s6
  # - [5,6, 9,4, 7,9] 
  # - [9,12, 17,7, 11,15] 
  # - [13,18, 15,21, 29,12] 
  # - [23,31, 46,20, 70,35]
# YOLOv5 v6.0 backbone   💊   efficientnetv2 【 参照网络结构-善常分类任务，目标检测稍次（obj/box/cls损失较大）】 理论精准度与swintransformer一样,？？？
backbone:
  [[-1, 1, stem, [24, 3, 2]],  # 0-P1/2 efficientnetv2 一开始是Stem = 普通的卷积+bn+激活  640*640*3 --> 320*320*24
#                    # [out_channel,kernel_size,stride,expansion,se_ration]
                     #[[输出，内核、步幅、填充、组]  enfficientnetv2 
   [-1, 2, FusedMBConv, [24, 3, 1, 1, 0]], # 1 2个FusedMBConv=3*3conv+se+1*1conv   320*320*24-->320*320*24      阉割了卷积步骤，主要为部署移动端，不追求模型大小时，不建议使用

   [-1, 1, FusedMBConv, [48, 3, 2, 4, 0]], # 2 这里strid2=2，特征图尺寸缩小一半，expansion=4输出特征图的深度变为原来的4倍 320*320*24-->160*160*48
   [-1, 3, FusedMBConv, [48, 3, 1, 4, 0]], # 3 EfficientNetV2结构，轻量化   ---自适应图像大小因子

   [-1, 1, FusedMBConv, [64, 3, 2, 4, 0]], # 4 160*160*48-->80*80*64
   [-1, 3, FusedMBConv, [64, 3, 1, 4, 0]], # 5   “扩张，分离，投影”理论>conv操作

   [-1, 1, MBConv, [128, 3, 2, 4, 0.25]], # 6  这里strid2=2，特征图尺寸缩小一半， 40*40*128    c3
   [-1, 5, MBConv, [128, 3, 1, 4, 0.25]], # 7

   [-1, 1, MBConv, [160, 3, 2, 6, 0.25]], # 8 这里 strid2=2，特征图尺寸缩小一半，20*20*160    c3
   [-1, 8, MBConv, [160, 3, 1, 6, 0.25]], # 9   stage5步长1

   [-1, 1, MBConv, [256, 3, 2, 4, 0.25]], # 10 这里strid2=2，特征图尺寸缩小一半，10*10*160  替换c3
   [-1, 14, MBConv, [256, 3, 1, 4, 0.25]], # 11
  
  #  [-1, 3, C3, [1024]],
  #  [-1, 3, CBAM, [1024]], #  13💊backbone第n层数添加就在head中注意相应添加层💊  head用多层concat结合 通道不匹配，256--1024（MBconv）--替换相同即可，通道同上
   [-1, 1, SPPF, [1024, 5]], #12 
  ]
# YOLOv5 v6.0 head   head层注意力机制不稳定
head:
  [[-1, 1, Conv, [512, 1, 1]], # 13  10*10
   [-1, 1, nn.Upsample, [None, 2, 'nearest']], # 14  20*20
   [[-1, 9], 1, Concat, [1]],  # 15 cat backbone P4 15  这里特征图大小为20*20，所以应该和9号连接💣   视MBconv为c3
   [-1, 3, C3, [512, False]],  # 16 20*20
   #[-1, 3, CBAM, [512]],  #💊 对应c3大小  17

   [-1, 1, Conv, [256, 1, 1]], #17  20*20  
   [-1, 1, nn.Upsample, [None, 2, 'nearest']], #18 40*40
   [[-1, 7], 1, Concat, [1]],  # cat backbone P3 19  7号特征图大小也是40*40💣   视MBconv为c3
   [-1, 3, C3, [256, False]],  # 20 (P3/8-small)  
   #[-1, 3, CBAM, [256]],  #💊  22

   [-1, 1, Conv, [256, 3, 2]],  #21  卷积步长为2，所以特征图尺寸缩小，为 20*20    
   [[-1, 17], 1, Concat, [1]],  # cat head P4  17层的特征图也是20*20💣   [[-1, 17]--->[[-1, 18]✅
   [-1, 3, C3, [512, False]],  # 23 (P4/16-medium) 
   #[-1, 3, CBAM, [512]],  #💊 26
    
   [-1, 1, Conv, [512, 3, 2]],  # 24  10*10    
   [[-1, 13], 1, Concat, [1]],  # cat head P5  13层的特征图大小就是10*10 💣 BiFPN_Concat2  [[-1, 13]-->[[-1, 14]☑️✅
   [-1, 3, C3, [1024, False]], # 26 (P5/32-large)
   #[-1, 3, CBAM, [1024]],  #💊  30 head结合注意detect对应c3检测层--conv/cat可能不行

   #三个检测头，对应anchors，分别来自24，27，30，层 选用头部c3
   [[20, 23, 26], 1, Detect, [nc, anchors]],  #✔️ Detect(P3, P4, P5)  [20, 23, 26]-->[21, 24, 27]       +3
  ]
# ✒️SwinStage 模块和 EfficientNetV2 中已经引入了自注意力机制✒️添加cbam空间通道时需要调整，冲突较大
# " 
# # [[24, 27, 30], 1, Detect, [nc, anchors]] 检测层都是c3  cat/add层c3/conv平分
# #
# #
# v5s6
# head:
#   [[-1, 1, Conv, [768, 1, 1]],  #另增加768🚀    
#    [-1, 1, nn.Upsample, [None, 2, 'nearest']], #上采样，wx2，hx2  最近邻插值
#    #[-1, 1, nn.ConvTranspose2d, [768, 4, 2, 1, 0, 768]], #设置转置卷积
#    [[-1, 8], 1, BiFPN_Concat2, [1]],  # cat backbone P5              Concat, [1]]--->   BIFPN_Add2, [384,384]],---464/s   ---576/m
#    [-1, 3, C3, [768, False]],  # 15

#    [-1, 1, Conv, [512, 1, 1]],
#    [-1, 1, nn.Upsample, [None, 2, 'nearest']],  
#    [[-1, 6], 1, BiFPN_Concat2, [1]],  # cat backbone P4                  Concat, [1]]--->   BIFPN_Add2, [256,256]]   --312/s   --384/m
#    [-1, 3, C3, [512, False]],  # 19

#    [-1, 1, Conv, [256, 1, 1]],       #backbone上添加层数head后9层添加
#    [-1, 1, nn.Upsample, [None, 2, 'nearest']],    
#    [[-1, 4], 1, BiFPN_Concat2, [1]],  # cat backbone P3    🚀                Concat 更换bifpn_Add,相应更改通道    Concat, [1]]--->BIFPN_Add2, [128, 128]],---160/s---192/m
#    [-1, 3, C3, [256, False]],  # 23 (P3/8-small)

#    [-1, 1, Conv, [256, 3, 2]], 
#    #[-1, 1, nn.Upsample, [None, 2, 'nearest']],  
#    [[-1, 21], 1, BiFPN_Concat2, [1]],  # cat head P4   🚀               +1     Concat, [1]],  --->[128, 128]],        --160/s   --192/m
#    [-1, 3, C3, [512, False]],  # 26 (P4/16-medium)

#    [-1, 1, Conv, [512, 3, 2]],
#    [[-1, 17], 1, BiFPN_Concat2, [1]],  # cat head P5              +1           Concat, [1]],--->[256, 256]],     ---312/s  ---384/m
#    [-1, 3, C3, [768, False]],  # 29 (P5/32-large)

#    [-1, 1, Conv, [768, 3, 2]],    #另增768🚀
#    [[-1, 13], 1, BiFPN_Concat2, [1]],  # cat head P6              +1      Concat, [1]],--->[384, 384]],    -----464/s    --576/m
#    [-1, 3, C3, [1024, False]], # 32 (P6/64-xlarge)  

#    [[24, 27, 30, 33], 1, Detect, [nc, anchors]],
   
# 